{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Install"]},{"cell_type":"code","execution_count":45,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"execution":{"iopub.execute_input":"2022-12-13T06:22:24.290536Z","iopub.status.busy":"2022-12-13T06:22:24.289569Z","iopub.status.idle":"2022-12-13T06:23:00.478740Z","shell.execute_reply":"2022-12-13T06:23:00.477299Z","shell.execute_reply.started":"2022-12-13T06:22:24.290427Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (4.25.1)Note: you may need to restart the kernel to use updated packages.\n","\n","Requirement already satisfied: requests in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from transformers) (2.28.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from transformers) (0.11.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from transformers) (0.13.2)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from transformers) (22.0)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from transformers) (1.23.5)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from transformers) (3.8.2)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from transformers) (4.64.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: colorama in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from requests->transformers) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from requests->transformers) (1.26.13)\n","Requirement already satisfied: torch in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (1.13.0)\n","Requirement already satisfied: typing_extensions in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from torch) (4.4.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: underthesea in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (1.3.5)\n","Requirement already satisfied: python-crfsuite>=0.9.6 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from underthesea) (0.9.8)\n","Requirement already satisfied: nltk in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from underthesea) (3.7)\n","Requirement already satisfied: unidecode in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from underthesea) (1.3.6)\n","Requirement already satisfied: underthesea-core==0.0.5a2 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from underthesea) (0.0.5a2)\n","Requirement already satisfied: joblib in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from underthesea) (1.2.0)\n","Requirement already satisfied: tqdm in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from underthesea) (4.64.1)\n","Requirement already satisfied: Click>=6.0 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from underthesea) (8.1.3)\n","Requirement already satisfied: scikit-learn in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from underthesea) (1.2.0)\n","Requirement already satisfied: requests in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from underthesea) (2.28.1)\n","Requirement already satisfied: PyYAML in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from underthesea) (6.0)\n","Requirement already satisfied: colorama in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from Click>=6.0->underthesea) (0.4.6)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from nltk->underthesea) (2022.10.31)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from requests->underthesea) (2.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from requests->underthesea) (1.26.13)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from requests->underthesea) (2022.9.24)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from requests->underthesea) (3.4)\n","Requirement already satisfied: numpy>=1.17.3 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from scikit-learn->underthesea) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from scikit-learn->underthesea) (1.9.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mravo\\miniconda3\\envs\\ml\\lib\\site-packages (from scikit-learn->underthesea) (3.1.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install transformers\n","%pip install torch\n","%pip install underthesea"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Import"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T06:24:13.350775Z","iopub.status.busy":"2022-12-13T06:24:13.350312Z","iopub.status.idle":"2022-12-13T06:24:22.026739Z","shell.execute_reply":"2022-12-13T06:24:22.025658Z","shell.execute_reply.started":"2022-12-13T06:24:13.350730Z"},"trusted":true},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torch.nn as nn\n","from torch.optim import Adam\n","from torch.utils.data import DataLoader\n","from underthesea import word_tokenize\n","from transformers import get_linear_schedule_with_warmup, AutoTokenizer, AutoModel\n","import torch.nn.functional as F\n","from torchvision.transforms import ToTensor\n","from PIL import Image\n","import requests"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Const"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T06:24:22.029102Z","iopub.status.busy":"2022-12-13T06:24:22.028547Z","iopub.status.idle":"2022-12-13T06:24:22.035831Z","shell.execute_reply":"2022-12-13T06:24:22.034185Z","shell.execute_reply.started":"2022-12-13T06:24:22.029071Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","EPOCHS = 2\n","MAX_LEN = 256\n","BATCH_SIZE = 4\n","LR = 2e-4\n","# with open('drive/MyDrive/Colab_Notebooks/Foody_data/Stopwords.txt', 'r', encoding=\"utf-8\") as f:\n","#     stop_set = set(m.strip() for m in f.readlines())\n","#     stopwords = list(frozenset(stop_set))\n","\n","torch.cuda.empty_cache()\n","print(device)\n","# df = pd.read_csv('/kaggle/input/int3405-sentiment-analysis-problem/full_train.csv')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Dataset and Models"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T06:24:22.038271Z","iopub.status.busy":"2022-12-13T06:24:22.037875Z","iopub.status.idle":"2022-12-13T06:24:22.062352Z","shell.execute_reply":"2022-12-13T06:24:22.061085Z","shell.execute_reply.started":"2022-12-13T06:24:22.038232Z"},"jupyter":{"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["class MyDataset(torch.utils.data.Dataset):\n","    def __init__(self, df):\n","        self.df = df\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n","#         self.stopwords = stopwords\n","    \n","    def __len__(self):\n","        return len(self.df)\n","\n","    def preprocess(self, s):\n","        s = str(s)\n","        s = s.lower()\n","        s = ''.join(e for e in s if e.isalnum() or e == ' ')\n","        return word_tokenize(s, format='text')\n","        # return ' '.join(e for e in s.split(' ') if e not in self.stopwords)\n","        \n","    def get_image(self, url):\n","        return ToTensor()(Image.open(requests.get(url, stream=True).raw).resize((28, 28))).to(device)\n","\n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        comment = self.preprocess(row['Comment'])\n","\n","        encoding = self.tokenizer.encode_plus(\n","            comment,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length=MAX_LEN,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_token_type_ids=False,\n","            return_tensors='pt',\n","        )\n","        \n","        return {\n","            'comment': comment,\n","            'input_ids': torch.flatten(encoding['input_ids']).to(device=device),\n","            'attention_masks': torch.flatten(encoding['attention_mask']).to(device=device),\n","            'targets': torch.tensor(row['Rating'], dtype=torch.long).to(device),\n","            \"images\": self.get_image(row['image_urls'][2:-2].split(\"', '\")[0]),\n","        } if self.df.shape[1] == 6 else {\n","            'comment': comment,\n","            'input_ids': torch.flatten(encoding['input_ids']).to(device=device),\n","            'attention_masks': torch.flatten(encoding['attention_mask']).to(device=device),\n","            \"images\": self.get_image(row['image_urls'][2:-2].split(\"', '\")[0]),\n","        }\n","\n","class MyModel(torch.nn.Module):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n","        self.drop = nn.Dropout(p=0.3)\n","        self.fc = nn.Linear(self.bert.config.hidden_size, 2)\n","        nn.init.normal_(self.fc.weight, std=0.02)\n","        nn.init.normal_(self.fc.bias, 0)\n","\n","    def forward(self, input):\n","        _, output = self.bert(\n","            input_ids=input['input_ids'],\n","            attention_mask=input['attention_masks'],\n","            return_dict=False\n","        )\n","\n","        x = self.drop(output)\n","        x = self.fc(x)\n","        return x\n","\n","class Basic_CNN_Module(nn.Module):\n","    def __init__(self) -> None:\n","        super(Basic_CNN_Module, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, 3, 1, 1)\n","        self.relu1 = nn.ReLU()\n","        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n","        self.relu2 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(3136, 128)\n","        self.relu3 = nn.ReLU()\n","        self.fc2 = nn.Linear(128, 2)\n","\n","    def forward(self, input):\n","        x = input['images']\n","        x = self.conv1(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.relu1(x)\n","        \n","        x = self.conv2(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.relu2(x)\n","        x = self.dropout1(x)\n","        \n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = self.relu3(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        return x"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Functions"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T06:24:22.066074Z","iopub.status.busy":"2022-12-13T06:24:22.065537Z","iopub.status.idle":"2022-12-13T06:24:22.087125Z","shell.execute_reply":"2022-12-13T06:24:22.086003Z","shell.execute_reply.started":"2022-12-13T06:24:22.066037Z"},"trusted":true},"outputs":[],"source":["def train(model, img_model, loss_func, img_loss_func, optimizer, img_optimizer, data_loader, lr_scheduler, epoch):\n","    print(f'Epoch {epoch}: ')\n","    model.train()\n","    img_model.train()\n","    losses = []\n","    correct = 0\n","\n","    for input in data_loader:\n","        optimizer.zero_grad()\n","        img_optimizer.zero_grad()\n","        outputs = model(input)\n","        img_outputs = img_model(input) #img\n","\n","        loss = loss_func(outputs, input['targets'])\n","        img_loss = img_loss_func(img_outputs, input['targets']) #img\n","        # pred = torch.round((2*torch.max(outputs, dim=1)[1] + torch.max(img_outputs, dim=1)[1])/3)\n","        _, pred = torch.max(2*outputs + img_outputs, dim=1)\n","\n","        correct += torch.sum(pred == input['targets'])\n","        losses.append(loss.item() + img_loss.item())\n","        loss.backward()\n","        img_loss.backward() #img\n","        img_optimizer.step() #img\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        lr_scheduler.step()\n","\n","    print(f'Train Accuracy: {correct.double()/len(data_loader.dataset)} Loss: {np.mean(losses)}')\n","\n","def test(model, img_model, data_loader, loss_func, img_loss_func):\n","    model.eval()\n","    img_model.eval()\n","    losses = []\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for input in data_loader:\n","            outputs = model(input)\n","            img_outputs = img_model(input) #img\n","\n","            # pred = torch.round((2*torch.max(outputs, dim=1)[1] + torch.max(img_outputs, dim=1)[1])/3)\n","            _, pred = torch.max(2*outputs + img_outputs, dim=1)\n","\n","            loss = loss_func(outputs, input['targets'])\n","            img_loss = img_loss_func(img_outputs, input['targets']) #img\n","            correct += torch.sum(pred == input['targets'])\n","            losses.append(loss.item() + img_loss.item())\n","    \n","        print(f'Test Accuracy: {correct.double()/len(data_loader.dataset)} Loss: {np.mean(losses)}')\n","\n","def get_dataloader():\n","    df = pd.read_csv('Data/full_train.csv')\n","    df = df.dropna()\n","    # shuffle the DataFrame rows\n","    df = df.sample(frac = 1)\n","    train_df, test_df = train_test_split(df, train_size=0.7)\n","    train_dataloader = DataLoader(MyDataset(train_df), batch_size=BATCH_SIZE, shuffle=True)\n","    test_dataloader = DataLoader(MyDataset(test_df), batch_size=BATCH_SIZE, shuffle=True)\n","    return train_dataloader, test_dataloader\n","\n","def predict(model: torch.nn.Module, img_model: torch.nn.Module):\n","    df = pd.read_csv('Data/test.csv')\n","    dataloader = DataLoader(MyDataset(df), batch_size=BATCH_SIZE, shuffle=False)\n","    n = df.shape[0]\n","    predicted = torch.Tensor([]).to(device=device)\n","    with torch.no_grad():\n","        for input in dataloader:\n","#             _, pred = torch.max(model(input), 1)\n","            # pred = torch.round((2*torch.max(model(input), dim=1)[1] + torch.max(img_model(input), dim=1)[1])/3)\n","            _, pred = torch.max(2*model(input) + img_model(input), dim=1)\n","            predicted = torch.concat((predicted, pred), dim=0)\n","            if (predicted.shape[0]%(64*5) == 0 or predicted.shape[0] == n):\n","                print(f'Running: {100 * predicted.shape[0] / n}%')\n","    assert predicted.shape[0] == n\n","    df['Rating'] = predicted.tolist()\n","    submission = pd.concat([df['RevId'], df['Rating']], axis=1)\n","    submission.to_csv(f'Results/submission.csv', index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Setup"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T06:24:22.088814Z","iopub.status.busy":"2022-12-13T06:24:22.088477Z","iopub.status.idle":"2022-12-13T06:24:45.587696Z","shell.execute_reply":"2022-12-13T06:24:45.586582Z","shell.execute_reply.started":"2022-12-13T06:24:22.088783Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["model = torch.load('Model/model.pt', map_location=torch.device(device))\n","cnn = torch.load('Model/cnn.pt', map_location=torch.device(device))\n","# model = MyModel().to(device)\n","# cnn = Basic_CNN_Module().to(device)\n","loss_func = torch.nn.CrossEntropyLoss()\n","img_loss_func = torch.nn.CrossEntropyLoss()\n","optimizer = Adam(model.parameters(), lr=2e-5)\n","img_optimizer = Adam(cnn.parameters(), lr=LR)\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n","train_dataloader, test_dataloader = get_dataloader()\n","lr_scheduler = get_linear_schedule_with_warmup(\n","                optimizer, \n","                num_warmup_steps=0, \n","                num_training_steps=len(train_dataloader)*EPOCHS\n","            )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Train, save model"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T06:24:45.589662Z","iopub.status.busy":"2022-12-13T06:24:45.589216Z","iopub.status.idle":"2022-12-13T07:13:30.178684Z","shell.execute_reply":"2022-12-13T07:13:30.176711Z","shell.execute_reply.started":"2022-12-13T06:24:45.589630Z"},"trusted":true},"outputs":[],"source":["# for epoch in range(EPOCHS):\n","#     train(model=model, img_model=cnn, loss_func=loss_func, img_loss_func=img_loss_func, optimizer=optimizer, img_optimizer=img_optimizer, data_loader=train_dataloader, epoch=epoch, lr_scheduler=lr_scheduler)\n","#     test(model=model, img_model=cnn, data_loader=test_dataloader, loss_func=loss_func, img_loss_func=img_loss_func)\n","# torch.save(model, '/kaggle/working/model.pt')\n","# torch.save(cnn, '/kaggle/working/cnn.pt')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Run predict"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2022-12-13T07:13:30.183234Z","iopub.status.busy":"2022-12-13T07:13:30.182298Z","iopub.status.idle":"2022-12-13T07:13:30.193260Z","shell.execute_reply":"2022-12-13T07:13:30.191732Z","shell.execute_reply.started":"2022-12-13T07:13:30.183169Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["Running: 6.270821085635901%\n","Running: 12.541642171271802%\n","Running: 18.8124632569077%\n","Running: 25.083284342543603%\n","Running: 31.3541054281795%\n","Running: 37.6249265138154%\n","Running: 43.895747599451305%\n","Running: 50.166568685087206%\n","Running: 56.4373897707231%\n","Running: 62.708210856359%\n","Running: 68.9790319419949%\n","Running: 75.2498530276308%\n","Running: 81.52067411326671%\n","Running: 87.79149519890261%\n","Running: 94.06231628453851%\n","Running: 100.0%\n"]}],"source":["predict(model, cnn)"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[11,  3],\n","        [ 6, 13]])\n"]}],"source":["a = torch.tensor([[1, 1], [2, 2]])\n","b = torch.tensor([[9, 1], [2, 9]])\n","print(2*a+b)"]}],"metadata":{"kernelspec":{"display_name":"ml","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"73adb7782d2199093edb3e18bf23e98b4bc6ff6f2317a5c619af07319dd995df"}}},"nbformat":4,"nbformat_minor":4}
